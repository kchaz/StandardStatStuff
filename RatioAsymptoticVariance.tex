\documentclass{article}

\usepackage[margin = .75in]{geometry}

\input{header}

\title{Asymptotic Variance of Ratio Estimator}
\author{Kyla Chasalow}
\date{May 2024}

\begin{document}

\maketitle

\section{Single Ratio Estimator}

Let $(X_i,Y_i)$ be i.i.d. random vectors with mean vector $(\mu_x,\mu_y)$, variances $\Var(X_i)=\sigma_x^2$, $\Var(Y_i)=\sigma_y^2$ and $\Cov(X_i,Y_i)=\sigma_{xy}$. Notice that $X_i$ and $Y_i$ are allowed to be dependent -- we only assume independence across $i$. By the multivariate central limit theorem, 

\begin{equation*} \sqrt{n} \frac{1}{n}\sum_{i=1}^{n}
    \left(\left(\begin{array}{c}
        X_i  \\
        Y_i  \\ 
    \end{array}\right) - \left(\begin{array}{c}
        \mu_x  \\
        \mu_y  \\ 
    \end{array}\right)\right) \xrightarrow{d}
    N\left(\left(\begin{array}{c}
        0  \\
        0 
    \end{array}\right),\left(\begin{array}{cc}
        \sigma_x^2  &  \sigma_{xy} \\
        \sigma_{xy} & \sigma_y^2 \\
    \end{array}\right)\right)
\end{equation*}

To calculate the asymptotic variance of the ratio estimate $\frac{\bar{X}_n}{\bar{Y}_n}$, apply the delta method with $f(a,b)=\frac{a}{b}$ and Jacobian

\begin{align*} 
J(a,b) &= \begin{bmatrix}
\frac{\partial f(a,b) }{\partial a} & \frac{\partial f(a,b) }{\partial b}
\end{bmatrix} = \begin{bmatrix}
\frac{1}{b} &  -\frac{a}{b^2}
\end{bmatrix}.
\end{align*}  

This yields

\begin{equation*}
\sqrt{n}\left(\frac{\bar{X}_n}{\bar{Y}_n} - \frac{\mu_x}{\mu_y}\right) \xrightarrow{d} N(0, JVJ^T)
\end{equation*}

where


\begin{align*}
    JVJ^T &= \begin{bmatrix}
\frac{1}{\mu_y} &  -\frac{\mu_x}{\mu_y^2}
\end{bmatrix} 
\begin{bmatrix}
    \sigma_x^2   &  \sigma_{xy}\\
    \sigma_{xy} & \sigma_y^2  \\
\end{bmatrix}
\begin{bmatrix}
\frac{1}{\mu_y} \\ -\frac{\mu_x}{\mu_y^2}
\end{bmatrix} =\begin{bmatrix}
  \frac{\sigma_x^2}{\mu_y} - \frac{\sigma_{xy}\mu_x}{\mu_y^2}  & \frac{\sigma_{xy}}{\mu_y} - \frac{\mu_x\sigma_{y}^2}{\mu_y^2} \\
\end{bmatrix}
\begin{bmatrix}
\frac{1}{\mu_y} \\ -\frac{\mu_x}{\mu_y^2}
\end{bmatrix} =
  \frac{\sigma_x^2}{\mu_y^2} - \frac{\sigma_{xy}\mu_x}{\mu_y^3}  - \frac{\sigma_{xy}\mu_x}{\mu_y^3} + \frac{\mu_x^2\sigma_{y}^2}{\mu_y^4} \\
\end{align*}

Overall, the asymptotic variance is

\begin{equation}\label{eq-ratiovar}
  \Var\left(\frac{\bar{X}}{\bar{Y}}\right)\rightarrow  \frac{\sigma_x^2}{\mu_y^2} - 2\frac{\sigma_{xy}\mu_x}{\mu_y^3}  + \frac{\mu_x^2\sigma_{y}^2}{\mu_y^4}
\end{equation}

\textbf{Comment:} if $X_i$ is mean-centered to begin with, i.e. $\mu_x=0$, then the expression simplifies to

\begin{equation}\label{eq-ratiovar}
  \Var\left(\frac{\bar{X}}{\bar{Y}}\right)\rightarrow  \frac{\sigma_x^2}{\mu_y^2}
\end{equation}

In this case, we can also obtain this result by a much simpler argument using Slutsky's theorem. That is, by the LLN, $\bar{Y}\xrightarrow{p} \mu_y$ and by the standard CLT, $\sqrt{n}\bar{X} \xrightarrow{d} N(0,\sigma_x^2)$  and hence by Slutsky, $\sqrt{n}\frac{\bar{X}}{\bar{Y}} \xrightarrow{d} N(0,\frac{\sigma_x^2}{\mu_y^2})$. We could show the same result for a generic $\frac{\bar{X}-\mu_x}{\bar{Y}}$, but if we are interested in $\frac{\bar{X}}{\bar{Y}}$, it is not clear how to immediately back that out since we would have to consider the asymptotic distribution of $\frac{\bar{X}-\mu_x}{\bar{Y}} + \frac{\mu_x}{\bar{Y}}$ and $\frac{1}{\bar{Y}}$ will not in general by asymptotically normal and is not independent of the other term.



\newpage 
\section{Collection of Ratio Estimators (Less Standard Extension)}

Now suppose we have i.i.d. vectors $(U_{i1},D_{i1},U_{i2},D_{i2},...,U_{ip},D_{ip})$ where $U$ stands for upper and $D$ for denominator. Suppose we have associated means $\mu_{u_j},\mu_{d_j}$, variances $\sigma_{u_j},\sigma_{d_j}$ for $j=1,...,p$, and covariances $\sigma_{u_ju_k}$, $\sigma_{u_jd_k}$, $\sigma_{d_jd_k}$. We can again apply the multivariate CLT

\begin{equation*} \sqrt{n} \frac{1}{n}\sum_{i=1}^{n}
    \left(\left(\begin{array}{c}
        U_{i1}  \\
        D_{i1}  \\ 
        \vdots \\ 
        U_{ip}\\
        D_{ip}\\
    \end{array}\right) - \left(\begin{array}{c}
        \mu_{u_1}  \\
        \mu_{d_1}  \\ 
        \vdots \\ 
        \mu_{u_p}  \\
        \mu_{d_p}  \\ 
    \end{array}\right)\right) \xrightarrow{d}
    N\left(\left(\begin{array}{c}
        0  \\
        0  \\
        \vdots \\
        0  \\
        0  \\
    \end{array}\right),\Sigma \right)
\end{equation*}

\begin{equation*}
    \Sigma = \left(\begin{array}{ccccc}
        \sigma_{u_1}^2  & \sigma_{u_1d_1}  & ... & \sigma_{u_1,u_p} & \sigma_{u_1d_p} \\
        \sigma_{d_1u_1} & \sigma_{d_1}^2   &... & \sigma_{d_1u_p} &\sigma_{d_1d_p} \\
        \vdots   & ... & \ddots  & ... & \vdots  \\
        \sigma_{u_pu_1} & \sigma_{u_pd_1} & ... & \sigma_{u_p}^2  & \sigma_{u_pd_p}^2 \\
        \sigma_{d_pu_1} & \sigma_{d_pd_1} & ... & \sigma_{d_pu_p} & \sigma_{d_p}^2 \\
    \end{array}\right) \in \mathbb{R}^{2p\times 2p}
\end{equation*}

Suppose we are interested in a the collection of ratios estimators $\frac{\bar{U}_j}{\bar{D}_j}$ for $j=1,...,p$. We could apply the transformation $f(a_1,b_1,...,a_p,b_p) = \left(\frac{a_1}{b_1},...,\frac{a_p}{b_p}\right)$ with Jacobian

\begin{align*} 
J(a_1,...,a_p,b_1,...,b_p) &= \begin{bmatrix}
\frac{\partial f_1 }{\partial a_1} & \frac{\partial f_1 }{\partial b_1} & ... &  \frac{\partial f_1 }{\partial a_p}&  \frac{\partial f_1 }{\partial b_p}\\
\vdots  & \vdots &  ... & \vdots & \vdots  \\
\frac{\partial f_p }{\partial a_1} & \frac{\partial f_p }{\partial b_1} & ... &  \frac{\partial f_p }{\partial a_p}   & \frac{\partial f_p }{\partial b_p}\\
\end{bmatrix} \\ 
&= \text{diag}\left(\begin{bmatrix}
\frac{1}{b_1} & -\frac{a_1}{b_1^2} \\ 
\end{bmatrix},...,\begin{bmatrix}
\frac{1}{b_p} & -\frac{a_p}{b_p^2} \\ 
\end{bmatrix} \right) \in \mathbb{R}^{p\times 2p}
\end{align*}  

where the diag notation means a block diagonal type matrix where in each row, only two elements are non-zero and in each column, only one element is non-zero. 

The asymptotic variance is $J\Sigma J^T$. As expected, the diagonal of this matrix is just the corresponding version of Equation (\ref{eq-ratiovar}) for that ratio estimator. For the covariance of the $j^{th}$ pair and the $k^{th}$ pair, we get

\begin{align*}
(J\Sigma J^T)_{j,k} &= 
    \begin{bmatrix}
  \frac{\sigma_{u_ju_k}}{\mu_{d_j}} - \frac{\sigma_{u_jd_k}\mu_{u_j}}{\mu_{d_j}^2}  & \frac{\sigma_{u_jd_k}}{\mu_{d_j}} - \frac{\mu_{u_j}\sigma_{d_j,d_k}}{\mu_{d_j}^2} \\
\end{bmatrix} \begin{bmatrix}
   \frac{1}{\mu_{d_k}} \\ 
    -\frac{\mu_{u_k}}{\mu_{d_k}^2} \\ 
\end{bmatrix}\\ 
&= \frac{\sigma_{u_ju_k}}{\mu_{d_j}\mu_{d_k}} - \frac{\sigma_{u_jd_k}\mu_{u_j}}{\mu^2_{d_j}\mu_{d_k}} - \frac{\sigma_{u_jd_k}\mu_{u_k}}{\mu_{d_j}\mu_{d_k}^2}  + \frac{\mu_{u_j}\mu_{u_k}\sigma_{d_jd_k}}{\mu_{d_j}^2\mu_{d_k}^2}
\end{align*}

That is 

\begin{equation*}
    \Cov\left(\frac{\bar{D}_j}{\bar{U}_j}, \frac{\bar{U}_k}{\bar{D}_k}\right) \rightarrow \frac{\sigma_{u_ju_k}}{\mu_{d_j}\mu_{d_k}} - \frac{\sigma_{u_jd_k}\mu_{u_j}}{\mu^2_{d_j}\mu_{d_k}} - \frac{\sigma_{u_jd_k}\mu_{u_k}}{\mu_{d_j}\mu_{d_k}^2}  + \frac{\mu_{u_j}\mu_{u_k}\sigma_{d_jd_k}}{\mu_{d_j}^2\mu_{d_k}^2}
\end{equation*}





\end{document}
